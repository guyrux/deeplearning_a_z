{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seção 4: Classificação binária - base breast cancer\n",
    "Os dados utilizados neste notebook foram tirados da página [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Formato do dataframe df_inputs: (569, 30)\n",
      "- Formato do dataframe df_outputs: (569, 1)\n"
     ]
    }
   ],
   "source": [
    "df_inputs = pd.read_csv(\"./data/entradas_breast.csv\")\n",
    "df_outputs = pd.read_csv(\"./data/saidas_breast.csv\")\n",
    "\n",
    "print(f\"\"\"- Formato do dataframe df_inputs: {df_inputs.shape}\n",
    "- Formato do dataframe df_outputs: {df_outputs.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das bases importadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_description = pd.DataFrame()\n",
    "# for feature in df_inputs.columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) e (455, 1)\n",
      "(114, 30) e (114, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, test_size=.2)\n",
    "\n",
    "print(f\"\"\"{X_train.shape} e {y_train.shape}\n",
    "{X_test.shape} e {y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_ann():\n",
    "    \"\"\"\n",
    "    Nessa função está a criação da rede neural com a camada de entrada (incluida na adição da primeira camada intermediária),\n",
    "    três camadas intermediárias e a camada de saída.\n",
    "    Como trata-se de um problema de classificação binária, a função de ativação usada na camada de saída é a sigmóide.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Camada de entrada e intermediária\n",
    "    model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))\n",
    "\n",
    "    # Camada intermediária ou oculta\n",
    "    model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Método de otimização a ser utilizado\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model_ann, epochs=100, batch_size=20, verbose=0)\n",
    "\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74        35\n",
      "           1       0.93      0.80      0.86        79\n",
      "\n",
      "    accuracy                           0.82       114\n",
      "   macro avg       0.79      0.83      0.80       114\n",
      "weighted avg       0.84      0.82      0.82       114\n",
      "\n",
      "[[30  5]\n",
      " [16 63]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred>.5,1,0)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560593220338983"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=model_ann, epochs=100, batch_size=20)\n",
    "\n",
    "cross_val = cross_val_score(estimator=model, X=df_inputs, y=df_outputs\n",
    "                            , cv=2, scoring=\"f1\", verbose=0, n_jobs=-1)\n",
    "\n",
    "cross_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting e dropout\n",
    "Para reduzir o risco de overfitting, pode-se usar o dropout. Esse método zera uma parcelas das entradas de camadas específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_ann():\n",
    "    \"\"\"\n",
    "    Nessa função está a criação da rede neural com a camada de entrada (incluida na adição da primeira camada intermediária),\n",
    "    três camadas intermediárias e a camada de saída.\n",
    "    Como trata-se de um problema de classificação binária, a função de ativação usada na camada de saída é a sigmóide.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Camada de entrada e intermediária\n",
    "    model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Camada intermediária ou oculta\n",
    "    model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Método de otimização a ser utilizado\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.25)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model_ann, epochs=100, batch_size=20, verbose=0)\n",
    "\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83        35\n",
      "           1       0.94      0.91      0.92        79\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.87      0.88      0.88       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "[[30  5]\n",
      " [ 7 72]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred>.5,1,0)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning de hiperparâmetros\n",
    "Vamos criar uma função baseada em uma criada anteriormente, mas dessa vez generalizaremos alguns dos hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ann_tunned(optimizer, loss, kernel_initializer, activation, neurons):\n",
    "    \"\"\"\n",
    "    Nessa função está a criação da rede neural com a camada de entrada (incluida na adição da primeira camada intermediária),\n",
    "    três camadas intermediárias e a camada de saída.\n",
    "    Como trata-se de um problema de classificação binária, a função de ativação usada na camada de saída é a sigmóide.\n",
    "    \n",
    "    Parâmetros:\n",
    "        optimizer, loss, kernel_initializer, activation, neurons\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Camada de entrada e intermediária\n",
    "    model.add(Dense(units=neurons, activation=activation, kernel_initializer=kernel_initializer, input_dim=30))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Camada intermediária ou oculta\n",
    "    model.add(Dense(units=neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Método de otimização a ser utilizado\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model_ann_tunned)\n",
    "\n",
    "parametros = {'batch_size': [10, 30],\n",
    "              'epochs': [50, 100],\n",
    "              'optimizer': ['adam', 'sgd'],\n",
    "              'loss': ['binary_crossentropy', 'hinge'],\n",
    "              'kernel_initializer': ['random_uniform', 'normal'],\n",
    "              'activation': ['relu', 'tanh'],\n",
    "              'neurons': [16, 8]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = parametros,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "melhores_parametros = grid_search.best_params_\n",
    "\n",
    "melhor_precisao = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ann_tunned(melhores_parametros)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo\n",
    "Abaixo um exemplo de como salvar os hiperparâmetros utilizados e os pesos obtidos no treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada e intermediária\n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Camada intermediária ou oculta\n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Método de otimização a ser utilizado\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"./model/model_ann_tunned.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"./model/model_ann_tunned.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98901486]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./model/model_ann_tunned.json\", \"r\") as file:\n",
    "    loaded_model = file.read()\n",
    "\n",
    "model = model_from_json(loaded_model)\n",
    "\n",
    "model.load_weights(\"./model/model_ann_tunned.h5\")\n",
    "\n",
    "registro_teste = X_test[1:2]\n",
    "\n",
    "y_pred = model.predict(registro_teste)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício para casa\n",
    "Nas aulas anteriores, chegamos no percentual de 84% de acerto utilizando validação cruzada juntamente com o uso de dropout . Com base nos parâmetros da rede neural que você aprendeu neste módulo, o objetivo é criar um modelo que ultrapasse a precisão de 90%. Para isso, você pode realizar alguns testes com base nos itens abaixo:\n",
    "\n",
    "Deixar a rede neural mais profunda, adicionando mais camadas ocultas (nas aulas nós fizemos os testes com somente duas camadas)\n",
    "Quando fizemos o tuning dos parâmetros chegamos a conclusão que os melhores resultados são obtidos se utilizarmos 8 neurônios nas camadas ocultas. Se aumentarmos essa quantidade para 32 será que teremos melhores resultados? E se colocarmos quantidade de neurônios diferentes nas camadas, como por exemplo: 16 neurônios na primeira camada e 8 na segunda?\n",
    "Aumentar e/ou diminuir o percentual de neurônios zerados com o dropout  (lembre-se de que quanto maior o percentual, mais a rede neural tem a tendência a entrar no problema do underfitting)\n",
    "Testar outras funções de ativação para as camadas ocultas, conforme as mostradas aqui na documentação do Keras\n",
    "Testar outras formas para a inicialização dos pesos, conforme mostradas aqui na documentação do Keras\n",
    "Testar outros otimizadores, conforme mostrados aqui na documentação do Keras. Após escolher o melhor otimizador, testar a configuração dos parâmetros learning rate , decay  e clipvalue \n",
    "Aumentar o número de épocas, bem como testas outros valores para o batch_size \n",
    "Para esta tarefa você pode utilizar como base o arquivo breast_cancer_cruzada.py  e utilizar o valor da variável media  para analisar o resultado da precisão.\n",
    "\n",
    "Assim que você conseguir o resultado de 90%, você deve postar as configurações utilizadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6107 - binary_accuracy: 0.4923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52        45\n",
      "           1       0.69      0.78      0.73        69\n",
      "\n",
      "    accuracy                           0.66       114\n",
      "   macro avg       0.64      0.62      0.63       114\n",
      "weighted avg       0.65      0.66      0.65       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada e intermediária\n",
    "model.add(Dense(units=8, activation='relu', kernel_initializer='random_uniform', input_dim=30))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Camada intermediária ou oculta\n",
    "model.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform'))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Método de otimização a ser utilizado\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.25)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_outputs, test_size=.2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.where(y_pred>.5,1,0)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
